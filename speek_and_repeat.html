<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Speech-to-Text with Audio Feedback</title>
<style>
  body { font-family: sans-serif; text-align: center; margin-top: 50px; }
  #indicator {
    display: inline-block;
    width: 30px;
    height: 30px;
    margin-left: 10px;
    border-radius: 50%;
    background-color: gray;
    vertical-align: middle;
    transition: width 0.1s, height 0.1s;
  }
  canvas { display: block; margin: 20px auto; background: #222; border-radius: 8px; }
</style>
</head>
<body>

<h2>Speak and Repeat - after 1 second of silence:</h2>
<p id="output">...</p>
<p>Listening indicator: <span id="indicator"></span></p>
<canvas id="waveform" width="600" height="100"></canvas>

<script>
const output = document.getElementById('output');
const indicator = document.getElementById('indicator');
const canvas = document.getElementById('waveform');
const ctx = canvas.getContext('2d');

const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
if (!SpeechRecognition) alert("Speech recognition not supported in this browser.");

let recognition;
let silenceTimeout;
let lastTranscript = "";
let audioContext, analyser, dataArray, source;

// Start microphone for visualization
async function setupAudio() {
    audioContext = new (window.AudioContext || window.webkitAudioContext)();
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    source = audioContext.createMediaStreamSource(stream);
    analyser = audioContext.createAnalyser();
    analyser.fftSize = 256;
    source.connect(analyser);
    dataArray = new Uint8Array(analyser.frequencyBinCount);
    drawWaveform();
}

// Draw waveform animation
function drawWaveform() {
    requestAnimationFrame(drawWaveform);
    if (!analyser) return;

    analyser.getByteTimeDomainData(dataArray);

    ctx.fillStyle = '#222';
    ctx.fillRect(0, 0, canvas.width, canvas.height);

    ctx.lineWidth = 2;
    ctx.strokeStyle = '#0f0';
    ctx.beginPath();

    const sliceWidth = canvas.width / dataArray.length;
    let x = 0;

    let sum = 0;
    for (let i = 0; i < dataArray.length; i++) {
        const v = dataArray[i] / 128.0 - 1.0;
        sum += Math.abs(v);
        const y = (v + 1) * canvas.height / 2;
        if (i === 0) ctx.moveTo(x, y);
        else ctx.lineTo(x, y);
        x += sliceWidth;
    }
    ctx.stroke();

    // Dynamic indicator size based on average amplitude
    const avg = sum / dataArray.length;
    const size = 20 + avg * 150; // 20px min, grow with volume
    indicator.style.width = `${size}px`;
    indicator.style.height = `${size}px`;
}

// Start speech recognition
function startListening() {
    recognition = new SpeechRecognition();
    recognition.lang = 'en-US';
    recognition.interimResults = true;
    recognition.continuous = true;

    indicator.style.backgroundColor = 'green';

    recognition.onresult = (event) => {
        let transcript = Array.from(event.results).map(r => r[0].transcript).join('');
        output.textContent = transcript;
        lastTranscript = transcript;

        if (silenceTimeout) clearTimeout(silenceTimeout);
        silenceTimeout = setTimeout(() => speakBack(lastTranscript), 1000);
    };

    recognition.onerror = (event) => {
        console.error("Error:", event.error);
        stopListening();
        setTimeout(startListening, 500);
    };

    recognition.onend = () => {
        indicator.style.backgroundColor = 'gray';
        setTimeout(startListening, 500);
    };

    recognition.start();
}

function speakBack(text) {
    if (!text) return;
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.onstart = () => { indicator.style.backgroundColor = 'gray'; };
    utterance.onend = () => { lastTranscript = ""; output.textContent = "..."; };
    speechSynthesis.speak(utterance);
}

function stopListening() {
    if (recognition) {
        recognition.onresult = null;
        recognition.onerror = null;
        recognition.onend = null;
        recognition.stop();
        recognition = null;
    }
    if (silenceTimeout) clearTimeout(silenceTimeout);
    indicator.style.backgroundColor = 'gray';
}

// Initialize
setupAudio();
startListening();
</script>
</body>
</html>
